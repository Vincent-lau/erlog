-module(worker).

-compile(export_all).

-include("../include/task_repr.hrl").
-include("../include/coor_params.hrl").
-include("../include/data_repr.hrl").

-include_lib("kernel/include/logger.hrl").

-define(coor_node, coor@vincembp).

start() ->
  true = net_kernel:connect_node(?coor_node),
  global:sync(), % make sure that worker sees the registered name
  Pid = global:whereis_name(coor),
  Prog = rpc:call(?coor_node, coordinator, get_prog, [Pid]),
  NumTasks = rpc:call(?coor_node, coordinator, get_num_tasks, [Pid]),
  work(Pid, Prog, NumTasks).

work(Pid, Prog, NumTasks) ->
  case rpc:call(?coor_node, coordinator, assign_task, [Pid]) of
    T = #task{type = evaluate,
              task_num = TaskNum,
              stage_num = StageNum} ->
      ?LOG_DEBUG(#{task_num => TaskNum, stage_num => StageNum}),
      % HACK no need to distinguish different stages for the FullDB, just keep adding
      FName1 = io_lib:format("~sfulldb-~w-~w", [?inter_dir, 1, TaskNum]),
      % TODO so here we are combining all full_dbs together, so when we generate
      % new atoms at each worker, we can avoid duplicates being written to the
      % deltas. The need for this is due to the fact that one atom that has been
      % written to the delta and indeed used in previous iterations are not necessarily
      % from that worker, but there is no chance for the generating worker to know
      % that atom has already been generated.
      FullDBs =
        [dbs:read_db(
           io_lib:format("~s-~w-~w", [?inter_dir ++ "fulldb", 1, X]))
         || X <- lists:seq(1, 4)],
      FullDB = lists:foldl(fun(DB, Acc) -> dbs:union(DB, Acc) end, dbs:new(), FullDBs),
      ?LOG_DEBUG(#{reading_fulldb_from_file_named => FName1,
                   full_db_read => dbs:to_string(FullDB)}),
      FName2 = io_lib:format("~stask-~w-~w", [?inter_dir, StageNum, TaskNum]),
      % we need to take the diff between this delta and the FullDB because our delta
      % might be generated by other workers
      DeltaDB = dbs:read_db(FName2),
      ?LOG_DEBUG(#{reading_deltas_from_file_named => FName2,
                   delta_db_read => dbs:to_string(DeltaDB)}),
      % use imm_conseq/3
      % need to store FullDB somewhere for later stages of evaluation
      % and this is not a static state, it changes every iteration
      % and is potentially huge, so this cost might be quite large
      {NewFullDB, NewDeltaDB} = eval:eval_seminaive_one(Prog, FullDB, DeltaDB),
      ?LOG_DEBUG(#{new_db => dbs:to_string(NewDeltaDB)}),
      % hash the new DB locally and write to disk
      % with only tuples that have not been generated before
      frag:hash_frag(NewDeltaDB, Prog, StageNum + 1, NumTasks, ?inter_dir ++ "task"),
      frag:hash_frag(
        dbs:diff(NewFullDB, FullDB), Prog, 1, NumTasks, ?inter_dir ++ "fulldb"),
      % call finish task on coordinator
      rpc:cast(?coor_node, coordinator, finish_task, [Pid, T]),
      % request new tasks
      io:format("stage-~w task-~w finished, requesting new task~n", [StageNum, TaskNum]),
      work(Pid, Prog, NumTasks);
    #task{type = wait} ->
      io:format("this is a wait task, sleeping for 3 sec~n"),
      timer:sleep(3000),
      work(Pid, Prog, NumTasks);
    #task{type = terminate} ->
      io:format("all done, time to relax~n");
    {badrpc, Reason} -> % TODO do I need to distinguish different errors
      io:format("getting task from coordinator failed due to ~p~n", [Reason])
  end.

stop() ->
  net_kernel:stop(),
  init:stop().

